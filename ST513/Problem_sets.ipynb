{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "vertical-touch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SAS Config named: oda\n",
      "Pandas module not available. Setting results to HTML\n",
      "SAS Connection established. Subprocess id is 286211\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import saspy\n",
    "my_session = saspy.SASsession()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "military-flight",
   "metadata": {},
   "source": [
    "# Set 6\n",
    "**1. What properties did we discuss that make an estimator good? What do each of those properties mean?**\n",
    "\n",
    "\"Ideally, an estimator would have a few properties\"\n",
    "- Be **unbiased**: on average, the estimator gives the (true) population value\n",
    "- Be **consistent**: as the sample size grows, the estimator should generally get closed and closer to the (true) population value\n",
    "- Have low variance/a small standard error: the estimator should have as little variation from dataset to dataset as possible\n",
    "- Ideally, we can determine (at least approximately) the pattern (distribution) in which we observe the estimator\n",
    "  - $\\bar{Y}$ is a common estimator of the population mean, $\\mu$\n",
    "  - The Central Limit Theorem tells us that we often observe $\\bar{Y}$ in a _normal_ distribution pattern\n",
    "\n",
    "**2. What is the idea of method of moments estimation?**\n",
    "\n",
    "Given a random sample, method of moments utilizes averages and population averages (expected values known as \"moments\") to create estimators.\n",
    "- Usually easy to find\n",
    "- Often are consistent\n",
    "- Distribution of the created estimator may be difficult to determine though\n",
    "\n",
    "Recap\n",
    "- Provides a straightforward way to create an estimator\n",
    "- Equate \"sample\" moments to \"population\" moments and solve\n",
    "- Generally, good properties (but not as good as MLEs)\n",
    "\n",
    "For a Binomial/Bernoulli MOM, set the sample average equal to the population average.\n",
    "\n",
    "**3. What is the idea of maximum likelihood estimation?**\n",
    "\n",
    "Maximum likelihood uses the assumed curve to find the \"most likely\" values of the parameters to produce the data we see.\n",
    "- Mathematically more difficult\n",
    "- ML estimators are generally consistent\n",
    "- Distribution of ML estimators can often be approximated with a normal curve\n",
    "\n",
    "**4. If we assume our data is a random sample from a normal population, what is the estimator of the mean? What is the estimator of the standard deviation? Is this the estimator you expect?**\n",
    "\n",
    "$\\bar{Y}$ is a common estimator of the population mean, $\\mu$. The Central Limit Theorem tells us that we often observe $\\bar{Y}$ in a normal distribution pattern.\n",
    "\n",
    "\n",
    "**5. What is the central limit theorem and why is it useful?**\n",
    "\n",
    "The CLT states that, for a random sample (iid) of size $n$ from a population with mean $\\mu$ and variances $\\sigma^2$, a good approximation to the distribution of the sample mean in \"large\" samples is \n",
    "\n",
    "$$\n",
    "\\bar{Y} \\sim N(\\mu, \\frac{\\sigma}{\\sqrt{n}}) \\\\\n",
    "\\text{with } Z = \\frac{\\bar{Y} - \\mu}{\\frac{\\sigma}{\\sqrt{n}}}\n",
    "$$\n",
    "\n",
    "**6. What is the goal of a confidence interval?**\n",
    "\n",
    "CI = range of values we are confident contain the true parameter (e.g. mean)\n",
    "- Often use 95% confidence\n",
    "  - Implies if we took 100 samples, each of the appropriate sample size, about 95 of intervals created would contain the population mean\n",
    "\n",
    "**7. Suppose we find a random sample of 24 business and find a 95% confidence interval for the average number of employees to be 24.4 to 42.6. We would say we are 95% confident the average number of employees for our population of businesses is between 24.4 and 42.6. What is meant by confidence?**\n",
    "\n",
    "In repeated samples, 95% of intervals created this way would capture the true average number of employees for our population of businesses.\n",
    "\n",
    "**8. Is the confidence interval form point estimate +/- MOE always appropriate?**\n",
    "\n",
    "\n",
    "**9. What is a confidence interval that can be used for the population mean in large samples? What interval can be used for small samples and what assumptions are needed?**\n",
    "\n",
    "\n",
    "**10. How do we check an assumption of normality?**\n",
    "\n",
    "\n",
    "**11. What is meant by the term two-sample t-interval? What are the two versions of this and which should we use generally?**\n",
    "\n",
    "Approximate confidence interval for $\\mu_{1}-\\mu_{2}$.\n",
    "\n",
    "- The samples must be independent of one another.\n",
    "- This is an exact interval (sort of).\n",
    "- If the sample size is large, you can replace the t distribution value with a Z value.\n",
    "- The degrees of freedom are estimated by software for the unequal variance case.\n",
    "- This might be referred to as a “two-sample t-interval.”\n",
    "\n",
    "Two versions - with and without equal variance. Generall,y use the unequal variance test.\n",
    "\n",
    "<center><img src=\"two_sample_t_interval.png\" style=\"width:800px\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proper-gibson",
   "metadata": {},
   "source": [
    "# Set 8\n",
    "**1. What is the goal of a hypothesis test?**\n",
    "\n",
    "We set up competing hypotheses (statements or claims about population parameters) to find evidence from our data to refute one of our hypotheses. \n",
    "\n",
    "Make claims about our population and see if our data refutes them. \n",
    "\n",
    "**2. What are the two conclusions we can make when doing a hypothesis test?**\n",
    "\n",
    "We can reject the null in favor of the alternative or fail to reject the null.\n",
    "\n",
    "Null hypothesis = \"status quo\", usually the one that says there is no difference, no new thing going on above and beyond what we already know. \n",
    "\n",
    "Alternative hypothesis: has a claim about the parameter that we would like to support or conclude. Assume that the null hypothesis is in effect and look at the data we obtained in an attempt to find evidence against that null hypothesis. \n",
    "\n",
    "**3. What are the two types of errors we can make? What symbols do we use for their probabilities?**\n",
    "1. We can reject the null, $H_{0}$, when the null is actually true. This is a Type I error. The probability of making a Type I error is called $\\alpha$. \n",
    "2. Fail to reject the null when the alternative is true. This is a Type II error. The probability of making a Type II error is called $\\beta$. \n",
    "\n",
    "**4. What is meant by ‘controlling alpha’ in a hypothesis test? How does this relate to not being able to accept the null hypothesis?**\n",
    "\n",
    "A Type I error is considered to be the worst, so we set the probability of making a Type I error (i.e. control $\\alpha$) to something very small. By doing so, we make sure that this type of error will only happen a very small number of times. \n",
    "\n",
    "We set up $\\alpha$ _assuming the null hypothesis is true_, so we're assuming the null is true when we're doing our calculations. Therefore, there is no way we can _accept_ the null hypothesis; we assumed it was true and did our calculations. Just because we got something that makes sense with what we assumed does not mean that our assumption was true (it just means we do not have evidence against it).  \n",
    "\n",
    "**5. What is a p-value? How can we use it to make a decision about our hypotheses?**\n",
    "\n",
    "p-values are one of the ways we make our decisions and one of the ways we give evidence against our null hypothesis. By definition, the p-value is the probability of seeing a sample result as extreme or more extreme than what we actually got _if the null hypothesis is true_. Everything we do with a p-value assumes the null is true. \n",
    "\n",
    "If we get a very, very small p-value, it means getting something like what we got (or worse) is very, very unlikely if the null is true. Very, very small p-values give evidence against the null hypothesis assumption that we made. Thus, we can make a rule that we will only reject the null hypothesis if the p-value is very small relative to $\\alpha$.  \n",
    "\n",
    "**6. What is power in hypothesis test?**\n",
    "\n",
    "This is related to the Type II error rate. Power is the probability that we reject $H_[0}$ when $H_{A}$ is true (i.e. the probability that we reject the null when we should). We want to have a low $\\alpha$, low $\\beta$, and high power.\n",
    "\n",
    "$$\n",
    "Power = 1 - \\beta\n",
    "$$\n",
    "\n",
    "We care most about controlling $\\alpha$ because a Type I error is the most serious. To manipulate $\\beta$ (or power), we usually change the sample size. As we increase the sample size, we should have a larger and larger power. \n",
    "\n",
    "**7. What is meant by the term two-sample t-test? Paired t-test? Z-test?**\n",
    "\n",
    "Two-sample t-test means we have 2 populations or 2 samples that we want to compare, and we're using a t-based test (i.e. something that relies on a t-distribution) to do the comparison and to make conclusions about those two samples. With a two-sample t-test, we _look at the difference in means_ and we use a test statistic that follows a t-distribution. The two samples are\n",
    "- independent of one another\n",
    "- each sample comes from a normally distributed population\n",
    "\n",
    "A paired t-test is the case where we're making the inference for means, but _we have paired data_. We still have 2 samples, but the samples are on the same units. These are no longer independent samples. We look at column 1 minus column 2 and we get a column of differences. We then do a t-test (something that uses a t-statistic) on that column to make an inference. The inferential objective is the average of the differences. The assumption we need is \n",
    "- the distribution of the differences is normally distributed\n",
    "\n",
    "Z-test is more broad than the above two and very, very common. It corresponds to any test statistic or any test that relies on normality (e.g. test for sample proportion, sample mean)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
