---
title: "Assignment 4"
author: "Maksim Nikiforov"
date: "9/11/2021"
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(haven)
library(readxl)
```

## Part 1 - Reading in basic raw data files

### 1. 

_If your working directory is myfolder/homework/, what path would you specify to get the file located at myfolder/MyData.csv?_


We can specify the path as `../MyData.csv`. The two periods take us to _myfolder_, the parent directory of _homework_.     

### 2. 

_Read in the **BreastCancer.dat** data file. Save the data to an R object called **cancerData**._


Visual Studio Code affirms that columns in _BreastCancer.dat_ are separated with tabs. Therefore, we can call the `read_tsv()` function to read the file into a 686 x 18 tibble.

```{r , echo=TRUE, eval=TRUE}
cancerData <- read_tsv(file = "BreastCancer.dat", col_names = TRUE)
cancerData
```

### 3.

_Using the **mosquito** files:_

  _a. Repeat the above process to read in the **mosquito.txt** file. Save the R object as **mosquitoData**._

To read in generally delimited files, we can use the `read_delim()` function and specify "$" in the function's _delim_ option.  

```{r , echo=TRUE, eval=TRUE}
mosquitoData <- read_delim(file = "mosquito.txt", delim = "&", col_names = TRUE)
mosquitoData

str(mosquitoData)

```

  _b. Repeat the above process to read in the **mosquito2.txt** file. Note that this file doesn’t contain column names. Use the same column names as the mosquitoData object from above. Use a function to retrieve the column names from the mosquitoData object. Save the R object as **mosquitoData2**._


As with _BreastCancer.dat_, we can use the `read_tsv()` function to read in files with tab-separated columns. Since observations begin in the first row in _mosquito2.txt_, we can retrieve our column names from the mosquitoData object by specifying `col_names = attributes(mosquitoData)$names` in lieu of `col_names = TRUE`.   

```{r , echo=TRUE, eval=TRUE}
mosquitoData2 <- read_tsv(file = "mosquito2.txt", col_names = attributes(mosquitoData)$names)
mosquitoData2
```
  _c. Combine the two datasets into one using the `rbind()` or `bind_rows()` function. Save the object as **mosquitoFullData**._


We can combine the **mosquitoData** and **mosquitoData2** data sets by specifying them as options in `rbind()`.

```{r , echo=TRUE, eval=TRUE}
mosquitoFullData <- rbind(mosquitoData, mosquitoData2)
mosquitoFullData
```

_d. Create and append two new variables to the **mosquitoFullData** object._

_- The **Response** column gives the lifetime of the mosquitos in days. One new variable should correspond to the lifetime of the mosquitos in hours._
_- The other new variable should take on one of 3 values: ‘short’, ‘medium’, and ‘long’ depending on the lifespan of the mosquito. If the mosquito lived less than 20 days the value should be short, between 20 and 40 (both inclusive) the value should be medium, otherwise the value should be long._


We can add new columns using the `mutate()` function. We can also use the vectorized function `if_else()` from the _dplyr_ package to assign one of three lifespans.   

```{r , echo=TRUE, eval=TRUE}
mosquitoFullData <- mosquitoFullData %>% mutate(responseHours = (Response * 24),
                                                lifeSpan = if_else(Response < 20, "short",
                                                                   if_else(Response <= 40, "medium",
                                                                           if_else(Response > 40, "long", "long"))))
mosquitoFullData
```

_e. Write the **mosquitoFullData** out to a .csv file with name of your choice for the outputted file._


We can write out data to a .csv format using the function `write_csv()`. 

```{r , echo=TRUE, eval=TRUE}
write_csv(x = mosquitoFullData, file = "mosquitoFullData.csv")
```


### 4. 

_Using the **effort.dta** file:_

_a. Note that this is a stata file and there is a function in the haven package that can read this in. Save the R object as effortData._


A quick look at [https://haven.tidyverse.org/](https://haven.tidyverse.org/) shows that Stata files can be read in using the `read_dta()` function. The _haven_ library had been initialized in the _setup_ chunk.  

```{r , echo=TRUE, eval=TRUE}
effortData <- read_dta(file = "effort.dta")
effortData
```

_b. Print to the console all observations where the change is greater than 15._


We can subset rows using the `filter()` function. 

```{r , echo=TRUE, eval=TRUE}
effortData %>% filter(change > 15)
```


### 5. 

_Read in the second sheet of the **Chickens** excel file. Save this object as **sheepData**._


Having initiated the _readxl_ library in the setup, we can use the `read_excel()` function with the _sheet = "Sheep"_ option to read in the second sheet of _Chickens.xlsx_.        

```{r , echo=TRUE, eval=TRUE}
sheepData <- read_excel("./Chickens.xlsx", sheet = "Sheep")
sheepData
```

## Part 2 - Databases

### 1. Google BigQuery

_We’ll start by connecting to a database - Google’s BigQuery database._

```{r, echo=TRUE, eval=TRUE}
#install the devtools package if you haven't already
#devtools::install_github("r-dbi/bigrquery")
library(bigrquery)
library(DBI)
con <- dbConnect(
bigrquery::bigquery(),
project = "publicdata",
dataset = "samples",
billing = 'publicdata-325802'
)
```

### 2. 

_We can see what tables are available for us to use with `dbListTables()`. Run this in the console first! You should be prompted to verify your credentials via a message in the R console. Be sure to check all the boxes there so you can complete the work below. This may need to be done in console in each subsequent session you open and want to knit and connect to this database._

```{r , echo=TRUE, eval=TRUE}
dbListTables(con)
```
### 3. 

_Now you can practice running **dplyr** or SQL queries. Place two queries that you did below (say one SQL query using `dbGetQuery` and one query using **dplyr**._

_- For `dbGetQuery`, check the help file for an example using SQL. In SQL code, LIMIT 10 will only grab 10 results (I’d add that to your query so you don’t have to wait long for the results)._

```{r, echo=TRUE, eval=TRUE}
dbGetQuery(con, "SELECT * FROM wikipedia LIMIT 10")
dbGetQuery(con, "SELECT * FROM shakespeare LIMIT 30")
```

_- For **dplyr** based queries, you can just include something like head(10) to return only 10 observations. Remember you need to add a function to your chain to actually return the data!_
help
```{r, echo=TRUE, eval=TRUE}
tbl(con, "shakespeare") %>% filter(word_count > 500) %>% head(10) %>% collect()
```

### 4. 

_It is good practice to disconnect from a database that you are accessing over the web or a server when you are done querying it. Use `dbDisconnect` to disconnect from the database._

```{r, echo=TRUE, eval=TRUE}
dbDisconnect(con)
```


### 1 - Local database. 

_Download the **chinook.db** database. Install and load the **DBI** and **RSQLite** packages, and load the **tidyverse** package. Use `dbConnect()` to connect to the this local database._

_You’ll only need two arguments to `dbConnect()`, the type of database and then the path to the database you’ve downloaded._

```{r, echo=TRUE, eval=TRUE}
library(DBI)
library(RSQLite)
library(tidyverse)
db <- dbConnect(
  RSQLite::SQLite(),
  './chinook.db'
)
```

### 2.

_Now print out the tables in the database using `dbListTables()`._

```{r, echo=TRUE, eval=TRUE}
dbListTables(db)
```

### 3. 

_Use `dbGetQuery()` or `tbl()` to grab and print out the **invoices** table and the **customers** table._

```{r, echo=TRUE, eval=TRUE}
invoicesTable <- tbl(db, "invoices") %>% collect()
customersTable <- tbl(db, "customers") %>% collect()

invoicesTable
customersTable
``` 

### 4. 

_Use an `inner_join()` to combine the two tables above by the **CustomerID** variable._

```{r , echo=TRUE, eval=TRUE}
customersInvoices <- inner_join(invoicesTable, customersTable)
customersInvoices
```
## Part 3 - Querying an API

### 1. 

_Install and load the **httr** and **jsonlite** packages if needed and load them in._

```{r , echo=TRUE, eval=TRUE}
library(httr)
library(jsonlite)
```

_Use `GET` from the **httr** package to return information about a topic of interest that has been in the news lately (store the result as an R object)._

We will query the API with the `/everything` endpoint to collect all news with the keyword "Astronomy" published since September 12. The results will be sorted by most popular news sources first.

```{r , echo=TRUE, eval=TRUE}
astronomyNews <- GET("https://newsapi.org/v2/everything?q=Astronomy&from=2021-09-12&sortBy=popularity&apiKey=2ea4b10211ad4d4cbea5373e3cbcb910")
astronomyNews
```

### 2.

_Inspect the structure of the returned object (we looked a function to do this!). Add `max.level = 1` as an argument to minimize the output._

We can determine the structure of an object using the `str()` function. 

```{r , echo=TRUE, eval=TRUE}
str(astronomyNews, max.level = 1)
```

### 3.

_Usually what you want is stored in something like content._

_Common steps:_
_- Grab the list element we want_
_- Convert it to characters using `rawToChar()` (here it will have a JSON structure)_
_- Convert it to a data frame with `fromJSON()` from the `jsonlite` package_

_Perform these steps._ 


We can pipe the raw bytes of _astronomyNews_ (`astronomyNews$content`) to the `rawToChar()` function for conversion to a character string. We can then pipe this string to the `fromJSON()` function to convert it to a list with an easy-to-view data from of our content.     

```{r , echo=TRUE, eval=TRUE}
astroContent <- astronomyNews$content %>% rawToChar() %>% fromJSON() 
astroContent
```
_Then look at the structure of the object!_

```{r , echo=TRUE, eval=TRUE}
str(astroContent)
```
